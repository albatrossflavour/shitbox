---
phase: 04-remote-health-and-stage-tracking
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - src/shitbox/storage/database.py
  - src/shitbox/storage/models.py
  - src/shitbox/health/thermal_monitor.py
  - src/shitbox/health/health_collector.py
  - src/shitbox/sync/batch_sync.py
  - src/shitbox/events/engine.py
  - tests/test_health_collector.py
autonomous: true
requirements:
  - HLTH-01

must_haves:
  truths:
    - "HealthCollector.collect() returns a Reading with cpu_temp, disk_pct, sync_backlog, and throttle_flags populated"
    - "batch_sync emits shitbox_disk_pct, shitbox_sync_backlog, and shitbox_throttle_flags Prometheus metrics for system readings"
    - "Schema v4 migration adds disk_percent, sync_backlog, throttle_flags columns to readings table and creates trip_state and waypoints_reached tables"
    - "ThermalMonitorService exposes last_throttled_raw as a public property"
  artifacts:
    - path: "src/shitbox/health/health_collector.py"
      provides: "HealthCollector value assembler"
      min_lines: 30
    - path: "tests/test_health_collector.py"
      provides: "Unit tests for HLTH-01"
      min_lines: 40
  key_links:
    - from: "src/shitbox/health/health_collector.py"
      to: "src/shitbox/health/thermal_monitor.py"
      via: "current_temp_celsius and last_throttled_raw properties"
      pattern: "thermal.*current_temp|thermal.*throttled_raw"
    - from: "src/shitbox/sync/batch_sync.py"
      to: "src/shitbox/storage/models.py"
      via: "Reading.disk_percent, sync_backlog, throttle_flags fields"
      pattern: "disk_percent|sync_backlog|throttle_flags"
---

<objective>
Add health metrics collection and Prometheus publication so the crew can monitor system
health remotely during connectivity windows.

Purpose: HLTH-01 requires CPU temp, disk %, sync backlog, and throttle state to appear in Grafana
when WireGuard is available. This plan builds the data layer (schema v4 migration, Reading model
extension) and the collection/publication path (HealthCollector, batch_sync metrics).

Output: HealthCollector class, schema v4 migration, extended Prometheus metrics, passing tests.
</objective>

<execution_context>
@/Users/tgreen/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tgreen/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-remote-health-and-stage-tracking/04-RESEARCH.md
@.planning/phases/03-thermal-resilience-and-storage-management/03-02-SUMMARY.md
@src/shitbox/storage/database.py
@src/shitbox/storage/models.py
@src/shitbox/health/thermal_monitor.py
@src/shitbox/sync/batch_sync.py
@src/shitbox/events/engine.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Schema v4 migration, Reading model extension, and database helpers</name>
  <files>
    src/shitbox/storage/database.py
    src/shitbox/storage/models.py
  </files>
  <action>
**models.py:** Add three new optional fields to the `Reading` dataclass:
- `disk_percent: Optional[float] = None`
- `sync_backlog: Optional[int] = None`
- `throttle_flags: Optional[int] = None`

**database.py — Schema v4 migration:**
Follow the existing `_migrate_to_v2` / `_migrate_to_v3` pattern. Create `_migrate_to_v4()`:

1. `ALTER TABLE readings ADD COLUMN disk_percent REAL` (try/except OperationalError for idempotency)
2. `ALTER TABLE readings ADD COLUMN sync_backlog INTEGER` (same pattern)
3. `ALTER TABLE readings ADD COLUMN throttle_flags INTEGER` (same pattern)
4. Create `trip_state` table:
   ```sql
   CREATE TABLE IF NOT EXISTS trip_state (
       key TEXT PRIMARY KEY,
       value_real REAL,
       value_text TEXT,
       updated_at TEXT DEFAULT (datetime('now'))
   );
   ```
5. Create `waypoints_reached` table:
   ```sql
   CREATE TABLE IF NOT EXISTS waypoints_reached (
       waypoint_index INTEGER PRIMARY KEY,
       name TEXT NOT NULL,
       reached_at TEXT NOT NULL,
       lat_at_reach REAL,
       lon_at_reach REAL
   );
   ```
6. Bump `SCHEMA_VERSION` to 4 and wire `_migrate_to_v4` into the migration chain.

**database.py — Update SQL statements:**
- Update `SCHEMA_SQL` to include the three new columns in the `readings` table CREATE statement
- Update `insert_reading()` to include `disk_percent`, `sync_backlog`, `throttle_flags` in the INSERT
- Update `insert_readings_batch()` similarly
- Update `_row_to_reading()` to read the three new columns

**database.py — Trip state helpers (for Plan 02):**
Add methods needed by the trip tracking plan:
- `get_trip_state(key: str) -> Optional[float]` — SELECT value_real from trip_state WHERE key = ?
- `get_trip_state_text(key: str) -> Optional[str]` — SELECT value_text from trip_state WHERE key = ?
- `set_trip_state(key: str, value: float) -> None` — UPSERT using ON CONFLICT(key) DO UPDATE
- `set_trip_state_text(key: str, value: str) -> None` — same pattern for value_text
- `record_waypoint_reached(waypoint_index: int, name: str, lat: float, lon: float) -> None` — INSERT OR IGNORE into waypoints_reached with reached_at = datetime('now')
- `get_reached_waypoints() -> set[int]` — SELECT waypoint_index FROM waypoints_reached, return as set

All write methods use `self._write_lock` following the existing pattern.
  </action>
  <verify>
    <automated>cd /Users/tgreen/dev/shitbox && python -c "from shitbox.storage.models import Reading; r = Reading.__dataclass_fields__; assert 'disk_percent' in r and 'sync_backlog' in r and 'throttle_flags' in r; print('OK')" && python -c "from shitbox.storage.database import TelemetryDatabase; print('Import OK')" && pytest tests/ -x -q</automated>
  </verify>
  <done>Reading dataclass has three new optional fields. Schema v4 migration creates health columns and trip/waypoint tables. insert_reading and _row_to_reading handle new fields. Trip state get/set helpers exist. All existing tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: HealthCollector, ThermalMonitor throttle property, batch_sync metrics, engine wiring, and tests</name>
  <files>
    src/shitbox/health/thermal_monitor.py
    src/shitbox/health/health_collector.py
    src/shitbox/sync/batch_sync.py
    src/shitbox/events/engine.py
    tests/test_health_collector.py
  </files>
  <action>
**thermal_monitor.py:** Add a public property `last_throttled_raw` that returns `self._last_throttled_raw` (currently a private attribute). This avoids HealthCollector making a separate vcgencmd subprocess call. Follow the `current_temp_celsius` property pattern.

**health_collector.py (NEW):** Create `src/shitbox/health/health_collector.py`:

```python
class HealthCollector:
    def __init__(
        self,
        thermal_monitor: ThermalMonitorService,
        batch_sync: Optional[BatchSyncService],
        data_dir: str,
    ) -> None:
        ...

    def collect(self) -> Optional[Reading]:
        """Assemble a system health Reading from current subsystem state."""
        cpu_temp = self._thermal.current_temp_celsius
        disk = shutil.disk_usage(self._data_dir)
        disk_pct = (disk.used / disk.total) * 100.0
        backlog = self._batch_sync.get_backlog_count() if self._batch_sync else 0
        throttle = self._thermal.last_throttled_raw
        return Reading(
            timestamp_utc=datetime.now(timezone.utc),
            sensor_type=SensorType.SYSTEM,
            cpu_temp_celsius=cpu_temp,
            disk_percent=disk_pct,
            sync_backlog=backlog,
            throttle_flags=throttle,
        )
```

Use `shutil.disk_usage()` for disk. Handle `FileNotFoundError` on disk_usage gracefully (return None if path does not exist). Use structlog for logging. Full type annotations. Follow the graceful degradation pattern — if any individual metric fails, log and continue with None for that field.

**batch_sync.py:** Extend `_readings_to_metrics()` in the existing `elif reading.sensor_type.value == "system":` block. Add three new metric emissions after the existing `shitbox_cpu_temp`:
- `shitbox_disk_pct` from `reading.disk_percent`
- `shitbox_sync_backlog` from `reading.sync_backlog` (cast to float)
- `shitbox_throttle_flags` from `reading.throttle_flags` (cast to float)
Each guarded by `if reading.{field} is not None`.

**engine.py:** Wire HealthCollector into the engine:
- Import HealthCollector
- In `__init__`, create `self._health_collector = None`
- In `start()`, after thermal_monitor is created, instantiate `HealthCollector(thermal_monitor, batch_sync, data_dir)` if thermal_monitor exists
- In `_record_telemetry()`, call `self._health_collector.collect()` and store the reading alongside other system readings (the existing `_read_system_status()` already writes a system reading — either replace that call with HealthCollector.collect() or call HealthCollector alongside it). The simplest approach: replace the existing inline system status read with HealthCollector.collect() since HealthCollector produces a superset of the same data.

**tests/test_health_collector.py (NEW):** Create tests covering:
- `test_health_collector_all_fields` — mock ThermalMonitorService (current_temp_celsius=65.0, last_throttled_raw=0), mock shutil.disk_usage, mock batch_sync.get_backlog_count(). Assert collect() returns Reading with all four fields.
- `test_health_collector_no_batch_sync` — batch_sync=None. Assert backlog is 0.
- `test_health_collector_no_temp` — current_temp_celsius=None. Assert Reading has cpu_temp_celsius=None but other fields populated.
- `test_health_metrics_in_prometheus` — create a Reading with all health fields populated, call _readings_to_metrics() (or equivalent), assert output contains shitbox_disk_pct, shitbox_sync_backlog, shitbox_throttle_flags metric tuples.
- `test_health_collector_graceful_disk_failure` — mock shutil.disk_usage to raise OSError. Assert collect() still returns a Reading (disk_percent=None).

Use `unittest.mock.patch` and `patch.object` following existing test patterns.
  </action>
  <verify>
    <automated>cd /Users/tgreen/dev/shitbox && pytest tests/test_health_collector.py -x -v && pytest tests/ -x -q</automated>
  </verify>
  <done>HealthCollector assembles four health metrics into a Reading. ThermalMonitorService exposes last_throttled_raw property. batch_sync emits shitbox_disk_pct, shitbox_sync_backlog, shitbox_throttle_flags. Engine wires HealthCollector into telemetry loop. All tests pass including new health collector tests.</done>
</task>

</tasks>

<verification>
1. `pytest tests/test_health_collector.py -x -v` — all health collector tests pass
2. `pytest tests/ -x -q` — full suite passes with no regressions
3. `ruff check src/shitbox/health/health_collector.py src/shitbox/storage/database.py src/shitbox/storage/models.py src/shitbox/sync/batch_sync.py` — no lint errors
4. `mypy src/shitbox/health/health_collector.py` — type check passes
</verification>

<success_criteria>
- HealthCollector.collect() returns a Reading with cpu_temp, disk_pct, sync_backlog, throttle_flags
- Schema v4 migration runs cleanly, creating health columns and trip/waypoint tables
- Prometheus batch sync emits four system metrics (including existing cpu_temp)
- ThermalMonitorService.last_throttled_raw property works
- All existing + new tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/04-remote-health-and-stage-tracking/04-01-SUMMARY.md`
</output>
